{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "ce9113a5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-01T01:51:28.804407Z",
     "start_time": "2023-06-01T01:51:28.782777Z"
    }
   },
   "outputs": [],
   "source": [
    "import jieba\n",
    "import jieba.posseg as pseg\n",
    "import jieba.analyse\n",
    "import string\n",
    "from string import punctuation\n",
    "import re\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import os\n",
    "from gensim.models import word2vec\n",
    "import gensim #这个包好像下载到python 3.10去了，这里估计用的是python3.10\n",
    "import logging\n",
    "import numpy as np\n",
    "from sklearn import svm, metrics\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "47c737a7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-01T01:52:22.531816Z",
     "start_time": "2023-06-01T01:52:22.522646Z"
    }
   },
   "outputs": [],
   "source": [
    "def remove_some(words):\n",
    "    words = words.replace(\"\\n\", \"\")\n",
    "    words = words.split(\"\\t\")\n",
    "    while '' in words:\n",
    "        words.remove('')\n",
    "    return words\n",
    "\n",
    "# 创建停用词list\n",
    "def stopwordslist(filepath):\n",
    "    stopwords = [line.strip() for line in open(filepath, 'r', encoding='utf-8').readlines()]\n",
    "    return stopwords\n",
    "\n",
    "# 对句子进行分词\n",
    "def seg_sentence(sentence):\n",
    "    sentence_seged = sentence.split(\"\\t\")\n",
    "    stopwords = stopwordslist('stopword.txt')  # 这里加载停用词的路径\n",
    "    outstr = ''\n",
    "    for word in sentence_seged:\n",
    "        if word not in stopwords:\n",
    "            if word != '\\n':\n",
    "                outstr += word\n",
    "                outstr += \" \"\n",
    "    return outstr\n",
    "\n",
    "def get_word_vector(path):\n",
    "    ip = open(path, 'r', encoding='utf-8')\n",
    "    content = ip.readlines()\n",
    "    #print(content)\n",
    "    vecs = []\n",
    "\n",
    "    for words in content:\n",
    "        # vec = np.zeros(2).reshape((1, 2))\n",
    "        vec = np.zeros(50).reshape((1, 50))\n",
    "        count = 0\n",
    "        # word = word.split(\"\\t\")\n",
    "        words = remove_some(words)\n",
    "        for word in words:\n",
    "            #print(\"*****\"+str(word))\n",
    "            try:\n",
    "                count += 1\n",
    "                # vec += model[word].reshape((1, 2))\n",
    "                vec += model.wv[word].reshape((1, 50)) #.reshape((1, 50)) \n",
    "                # print(vec)\n",
    "            except KeyError:\n",
    "                continue\n",
    "        vec /= count\n",
    "        vecs.append(vec)\n",
    "    return vecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "7d07cc07",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-01T02:30:50.374796Z",
     "start_time": "2023-06-01T02:30:48.780686Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-01 10:30:48,787 : INFO : collecting all words and their counts\n",
      "2023-06-01 10:30:48,793 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2023-06-01 10:30:48,910 : INFO : collected 10493 word types from a corpus of 202932 raw words and 21 sentences\n",
      "2023-06-01 10:30:48,911 : INFO : Creating a fresh vocabulary\n",
      "2023-06-01 10:30:48,966 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=1 retains 10493 unique words (100.00% of original 10493, drops 0)', 'datetime': '2023-06-01T10:30:48.966877', 'gensim': '4.3.0', 'python': '3.10.9 (main, Mar  1 2023, 12:33:47) [Clang 14.0.6 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2023-06-01 10:30:48,968 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=1 leaves 202932 word corpus (100.00% of original 202932, drops 0)', 'datetime': '2023-06-01T10:30:48.968611', 'gensim': '4.3.0', 'python': '3.10.9 (main, Mar  1 2023, 12:33:47) [Clang 14.0.6 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2023-06-01 10:30:49,049 : INFO : deleting the raw counts dictionary of 10493 items\n",
      "2023-06-01 10:30:49,051 : INFO : sample=0.001 downsamples 50 most-common words\n",
      "2023-06-01 10:30:49,051 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 170534.9062576334 word corpus (84.0%% of prior 202932)', 'datetime': '2023-06-01T10:30:49.051723', 'gensim': '4.3.0', 'python': '3.10.9 (main, Mar  1 2023, 12:33:47) [Clang 14.0.6 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2023-06-01 10:30:49,167 : INFO : estimated required memory for 10493 words and 50 dimensions: 9443700 bytes\n",
      "2023-06-01 10:30:49,168 : INFO : resetting layer weights\n",
      "2023-06-01 10:30:49,172 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-06-01T10:30:49.172717', 'gensim': '4.3.0', 'python': '3.10.9 (main, Mar  1 2023, 12:33:47) [Clang 14.0.6 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'build_vocab'}\n",
      "2023-06-01 10:30:49,173 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 10493 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2023-06-01T10:30:49.173851', 'gensim': '4.3.0', 'python': '3.10.9 (main, Mar  1 2023, 12:33:47) [Clang 14.0.6 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'train'}\n",
      "2023-06-01 10:30:49,396 : INFO : EPOCH 0: training on 202932 raw words (170349 effective words) took 0.2s, 780332 effective words/s\n",
      "2023-06-01 10:30:49,562 : INFO : EPOCH 1: training on 202932 raw words (170572 effective words) took 0.2s, 1052715 effective words/s\n",
      "2023-06-01 10:30:49,736 : INFO : EPOCH 2: training on 202932 raw words (170409 effective words) took 0.2s, 991700 effective words/s\n",
      "2023-06-01 10:30:49,917 : INFO : EPOCH 3: training on 202932 raw words (170693 effective words) took 0.2s, 956491 effective words/s\n",
      "2023-06-01 10:30:50,102 : INFO : EPOCH 4: training on 202932 raw words (170759 effective words) took 0.2s, 941330 effective words/s\n",
      "2023-06-01 10:30:50,103 : INFO : Word2Vec lifecycle event {'msg': 'training on 1014660 raw words (852782 effective words) took 0.9s, 918658 effective words/s', 'datetime': '2023-06-01T10:30:50.103059', 'gensim': '4.3.0', 'python': '3.10.9 (main, Mar  1 2023, 12:33:47) [Clang 14.0.6 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'train'}\n",
      "2023-06-01 10:30:50,103 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec<vocab=10493, vector_size=50, alpha=0.025>', 'datetime': '2023-06-01T10:30:50.103660', 'gensim': '4.3.0', 'python': '3.10.9 (main, Mar  1 2023, 12:33:47) [Clang 14.0.6 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'created'}\n",
      "2023-06-01 10:30:50,117 : INFO : Word2Vec lifecycle event {'fname_or_handle': './model_book', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2023-06-01T10:30:50.117182', 'gensim': '4.3.0', 'python': '3.10.9 (main, Mar  1 2023, 12:33:47) [Clang 14.0.6 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'saving'}\n",
      "2023-06-01 10:30:50,118 : INFO : not storing attribute cum_table\n",
      "2023-06-01 10:30:50,196 : INFO : saved ./model_book\n",
      "/var/folders/5c/f0y7h3ld7tzf7npwx1w2pnhr0000gn/T/ipykernel_70935/1297518283.py:46: RuntimeWarning: invalid value encountered in divide\n",
      "  vec /= count\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# generate_data(\"./ttt1.txt\")\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "sentences = word2vec.Text8Corpus(u\"./tt_digital.txt\")  # 加载语料\n",
    "if os.path.exists(\"./model_digital\"):\n",
    "    model = gensim.models.Word2Vec.load('./model_digital')\n",
    "else:\n",
    "    model = word2vec.Word2Vec(sentences, min_count=1,vector_size=50)  # 训练skip-gram模型 \n",
    "    model.save(\"./model_book\")\n",
    "# sentences = generate_data(\"./data11\")\n",
    "normal_path = open('./digital_positive_word_list.txt', 'r', encoding='utf-8')\n",
    "spam_path = open('./digital_negative_word_list.txt', 'r', encoding='utf-8')\n",
    "normal = get_word_vector('./digital_positive_word_list.txt')\n",
    "spam = get_word_vector('./digital_negative_word_list.txt')\n",
    "\n",
    "# normal = extendd(normal)\n",
    "# spam = extendd(spam)\n",
    "\n",
    "normal_tag = np.ones((len(normal)))\n",
    "spam_tag = np.zeros((len(spam)))\n",
    "# print(normal)\n",
    "train = normal + spam\n",
    "train_tag = normal_tag.tolist() + spam_tag.tolist()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(np.array(train, dtype='float64'),\n",
    "                                                    np.array(train_tag, dtype='float64'), test_size=0.30,\n",
    "                                                    random_state=0)  # 随机选择30%作为测试集，剩余作为训练集\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier  # 决策树分类器\n",
    "# clf = DecisionTreeClassifier(max_depth=8)        #神经网络分类器\n",
    "\n",
    "# clf = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(100, 100, 100, 100))\n",
    "# clf = svm.SVC()  # 使用RBF核   高斯核函数\n",
    "clf = svm.LinearSVC()  # 使用线性核\n",
    "X_train = np.squeeze(X_train)\n",
    "X_test = np.squeeze(X_test)\n",
    "y_train = np.squeeze(y_train)\n",
    "y_test = np.squeeze(y_test)\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "87186d50",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-01T01:51:45.891013Z",
     "start_time": "2023-06-01T01:51:45.828099Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#get_word_vector('./positive_word_list.txt')\n",
    "?word2vec.Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "8e871db6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-01T02:30:55.938649Z",
     "start_time": "2023-06-01T02:30:55.674370Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. ... 1. 1. 1.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hongruoyu/anaconda3/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "imp=SimpleImputer()\n",
    "\n",
    "X_train = imp.fit_transform(X_train)\n",
    "X_test = imp.fit_transform(X_test)\n",
    "\n",
    "\n",
    "clf_res = clf.fit(X_train, y_train)\n",
    "train_pred = clf_res.predict(X_train)\n",
    "test_pred = clf_res.predict(X_test)\n",
    "print(test_pred)\n",
    "#    accuracy = np.mean(test_pred == y_test)\n",
    "#   print(accuracy)\n",
    "#  print(metrics.classification_report(y_test, test_pred, target_names=X_test))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "482dcb10",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-01T02:31:09.305623Z",
     "start_time": "2023-06-01T02:31:09.266435Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "digital_svm\n",
      "train acc 0.5071428571428571 p 0.5038676020867062 r 0.9992864787727435 f1 0.6699354221478115\n",
      "==========================================\n",
      "test acc 0.505 p 0.501889962200756 r 0.9983291562238931 f1 0.6679709334823924\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "#train\n",
    "acc_1 = accuracy_score(y_train, train_pred)\n",
    "p_1=precision_score(y_train, train_pred)\n",
    "r_1=recall_score(y_train, train_pred)\n",
    "f1_1=f1_score(y_train, train_pred)\n",
    "\n",
    "#test\n",
    "acc_2 = accuracy_score(y_test, test_pred)\n",
    "p_2=precision_score(y_test, test_pred)\n",
    "r_2=recall_score(y_test, test_pred)\n",
    "f1_2=f1_score(y_test, test_pred)\n",
    "\n",
    "print(\"digital_svm\")\n",
    "print(\"train\",'acc', acc_1, 'p', p_1, 'r', r_1, 'f1', f1_1)#test\n",
    "\n",
    "print(\"==========================================\")\n",
    "print(\"test\",'acc', acc_2, 'p', p_2, 'r', r_2, 'f1', f1_2)#test\n",
    "#print(acc)\n",
    "#print(classification_report(y_test, test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58c4debd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
